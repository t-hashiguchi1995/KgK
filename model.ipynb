{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6bce76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 関連ライブラリのimport\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "#fold数\n",
    "folds = 5\n",
    "seeds = [42, 1234, 923, 628, 802]\n",
    "n = 27\n",
    "param_tune = False\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import gc\n",
    "gc.enable()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import japanize_matplotlib\n",
    "import seaborn as sns\n",
    "\n",
    "import mojimoji\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34192aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_csv(\"data/train_processed.csv\")\n",
    "# test = pd.read_csv(\"data/test_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbc16ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_csv(\"data/train_processed_add_groupby.csv\")\n",
    "# test = pd.read_csv(\"data/test_processed_add_groupby.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d9d241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_csv(\"data/train_processed_add_geocoding.csv\")\n",
    "# test = pd.read_csv(\"data/test_processed_add_geocoding.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1363a4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_csv(\"data/train_processed_add_groupby_geocoding.csv\")\n",
    "# test = pd.read_csv(\"data/test_processed_add_groupby_geocoding.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ce1489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_csv(\"data/train_processed_add_geocoding_meshcode.csv\")\n",
    "# test = pd.read_csv(\"data/test_processed_add_geocoding_meshcode.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefb379c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_csv(\"data/train_processed_add_geocoding_meshcode_crime.csv\")\n",
    "# test = pd.read_csv(\"data/test_processed_add_geocoding_meshcode_crime.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61ee356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_csv(\"data/train_processed_add_geocoding_meshcode_crime_landprice.csv\")\n",
    "# test = pd.read_csv(\"data/test_processed_add_geocoding_meshcode_crime_landprice.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb7d4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_csv(\"data/train_processed_add_geocoding_meshcode_crime_landprice_log_groupby.csv\")\n",
    "# test = pd.read_csv(\"data/test_processed_add_geocoding_meshcode_crime_landprice_log_groupby.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bada8bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train_processed_add_geocoding_meshcode_crime_landprice_ladmark_log_groupby.csv\")\n",
    "test = pd.read_csv(\"data/test_processed_add_geocoding_meshcode_crime_landprice_ladmark_log_groupby.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce47cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclusion = [\"所在地\", \"アクセス\", \"番地\", \"tokens\", \"丁目\", \"町\"]\n",
    "train = train.drop(exclusion, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b0720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_tune(data, target):\n",
    "    \"\"\"\n",
    "    パラメータチューニングもまとめてやろうとした残骸\n",
    "    \"\"\"\n",
    "    dtrain = lgb.Dataset(data, label=target)\n",
    "\n",
    "    params = {\n",
    "        'objective': \"regression\",\n",
    "        'metric':\"rmse\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "    }\n",
    "\n",
    "    tuner = lgb.LightGBMTunerCV(\n",
    "        params,\n",
    "        dtrain,\n",
    "        folds=KFold(n_splits=5),\n",
    "        callbacks=[early_stopping(100), log_evaluation(100)],\n",
    "        optuna_seed=42,\n",
    "    )\n",
    "\n",
    "    tuner.run()\n",
    "    \n",
    "    return tuner.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8217af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgbmのモデルを関数で定義しておく\n",
    "def fit_lgb(X_fit, y_fit, X_val, y_val, counter, feats, cat_col_indices, seed=42):\n",
    "    \"\"\"\n",
    "    全体モデルのパラメータ\n",
    "    \"\"\"\n",
    "    \n",
    "    lightgbm_params = {\n",
    "     'objective': \"regression\",\n",
    "     'metric':\"rmse\",\n",
    "     'learning_rate': 0.01, # 学習率(デフォルトは0.03 or auto)\n",
    "     'max_depth': -1, \n",
    "     'seed': seed, # random seed\n",
    "     'n_estimators':100000, # 学習回数\n",
    "     'n_jobs': -1,\n",
    "        'feature_pre_filter': False,\n",
    " 'lambda_l1': 6.984886757774584,\n",
    " 'lambda_l2': 1.2439642430435591e-05,\n",
    " 'num_leaves': 19,\n",
    " 'feature_fraction': 0.516,\n",
    " 'bagging_fraction': 1.0,\n",
    " 'bagging_freq': 0,\n",
    " 'min_child_samples': 20,\n",
    "    }\n",
    "    \n",
    "    model = lgb.LGBMRegressor(**lightgbm_params)\n",
    "     \n",
    "    model.fit(X_fit, y_fit, \n",
    "              eval_set=[(X_val, y_val)],\n",
    "              categorical_feature = cat_col_indices,\n",
    "              verbose=1000, # 1000 iterationごとに詳細を表示\n",
    "              early_stopping_rounds=500) # 500 iterationの間validation setの精度が向上しなかったら学習終了\n",
    "    \n",
    "    # validation setの予測結果を格納\n",
    "    cv_pred = model.predict(X_val)\n",
    "    \n",
    "    # 特徴量重要度を後で確認するためデータフレームに格納\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = feats\n",
    "    fold_importance_df[\"importance\"] = model.feature_importances_\n",
    "    fold_importance_df[\"fold\"] = counter + 1\n",
    "    \n",
    "    return model, cv_pred, fold_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7dfb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for seed in seeds:\n",
    "    # 目的変数\n",
    "    train_y = np.array(train['賃料'])\n",
    "    # idは特徴量には使えないので切り出しておく\n",
    "    train_ids = np.array(train['id'])\n",
    "    # idと賃料以外が特徴量になる\n",
    "    feats = [col for col in train.columns if col not in ['id','賃料']]\n",
    "\n",
    "    # カテゴリ変数のインデックス番号を取得\n",
    "    # lightgbmでは学習時にどの特徴量がカテゴリ変数なのか引数で指定できるが、\n",
    "    # 特徴量の名前ではなく特徴量の「インデックス番号」で指定する必要がある(バージョンによっても違うかも)\n",
    "    categorical_feats_name = ['方角','建物構造','区', \"railway\", \"公示価格_bin\"]\n",
    "    categorical_feats_indices = []\n",
    "    for col in categorical_feats_name:\n",
    "        categorical_feats_indices.append(list(train[feats].columns).index(col))\n",
    "\n",
    "    # KFoldで順々に学習⇒評価していくので、最終的にtrain set全体に対するRMSEを評価するため予測結果の格納場所を用意しておく\n",
    "    cv_preds = np.zeros(train.shape[0])\n",
    "    # kf = KFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    kf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    # kf.get_n_splits(train_ids, train_y)\n",
    "\n",
    "    # パラメータチューニングしようとした残骸\n",
    "    if param_tune==True:\n",
    "        lightgbm_params = param_tune(train[feats], train_y)\n",
    "\n",
    "    # 特徴量重要度格納用タプル\n",
    "    feature_importances = []\n",
    "    # モデル格納用タプル\n",
    "    seed_models = []\n",
    "    t0 = time.time()\n",
    "    for counter, ids in enumerate(kf.split(train_ids, train_y)):\n",
    "        print('\\nseed {} Fold {}'.format(seed, counter+1))\n",
    "        # training set\n",
    "        X_fit, y_fit = train[feats].values[ids[0]], train_y[ids[0]]\n",
    "        # validation set\n",
    "        X_val, y_val = train[feats].values[ids[1]], train_y[ids[1]]\n",
    "\n",
    "        model, cv_pred, fold_importance_df = fit_lgb(X_fit, y_fit, X_val, y_val, counter, feats, categorical_feats_indices)\n",
    "        # 該当するインデックスにvalidation setの予測結果を格納\n",
    "        cv_preds[ids[1]] += cv_pred\n",
    "        models.append(model)\n",
    "        feature_importances.append(fold_importance_df)\n",
    "        del X_fit, X_val, y_fit, y_val\n",
    "        gc.collect()\n",
    "\n",
    "    # trainデータ全体のRMSEを評価\n",
    "    rmse = np.sqrt(mean_squared_error(cv_preds,train_y))\n",
    "    print('Trainデータ全体のRMSE: {:.5f}'.format(rmse))\n",
    "\n",
    "    # 特徴量重要度のプロット\n",
    "    feature_importance_df = pd.concat(feature_importances)\n",
    "    mean_importance = feature_importance_df[[\"feature\", \"importance\"]].groupby('feature').mean()\n",
    "    feature_importance_df['mean_importance'] = feature_importance_df['feature'].map(mean_importance['importance'])\n",
    "    plt.figure(figsize=(8,24), facecolor='w')\n",
    "    #plt.rcParams[\"font.size\"] = 16\n",
    "    sns.barplot(x='importance', y='feature', \n",
    "                data=feature_importance_df.sort_values('mean_importance', ascending=False).iloc[:5 * 50])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    t1 = time.time()\n",
    "    elapsed_time = t1-t0\n",
    "    print(\"Elapsed time：{:.2f} sec\".format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee9c187",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "# submissionにidが必要なのでidは必ず確保しておく\n",
    "test_ids = test[\"id\"]\n",
    "\n",
    "test_preds = np.zeros(test.shape[0])\n",
    "# fold数分のモデルの予測結果を平均(アンサンブル)\n",
    "for model in tqdm(models):\n",
    "    test_preds += model.predict(test[feats].values)/len(models)\n",
    "\n",
    "submission = pd.DataFrame({\"id\":test_ids,\n",
    "                           \"賃料\":test_preds})\n",
    "\n",
    "# submissionのフォーマットにのっとって出力\n",
    "submission.to_csv(f\"./submission_log/submission_lgbm_{n}.csv\", sep=\",\", index=False, header=None)\n",
    "\n",
    "t1 = time.time()\n",
    "elapsed_time = t1-t0\n",
    "print(\"Elapsed time：{:.2f} sec\".format(elapsed_time))\n",
    "cv_pred_df = pd.DataFrame([cv_preds, train_y]).T\n",
    "cv_pred_df.columns = [\"cv_score\", \"true\"]\n",
    "cv_pred_df[\"error\"] = abs(cv_pred_df[\"cv_score\"] - cv_pred_df[\"true\"])\n",
    "cv_pred_df.to_csv(f\"./cv_log/cv_error_{n}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440b7de9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d97818",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7818ff96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c0a625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgbmのモデルを関数で定義しておく\n",
    "def fit_lgb_2(X_fit, y_fit, X_val, y_val, counter, feats, cat_col_indices, seed=42):\n",
    "    \"\"\"\n",
    "    一般人向けモデルのパラメータ\n",
    "    \"\"\"\n",
    "    \n",
    "    lightgbm_params = {\n",
    "     'objective': \"regression\",\n",
    "     'metric':\"rmse\",\n",
    "     'learning_rate': 0.01, # 学習率(デフォルトは0.03 or auto)\n",
    "     'max_depth': -1, \n",
    "     'seed': seed, # random seed\n",
    "     'n_estimators':100000, # 学習回数\n",
    "     'n_jobs': -1,\n",
    "      'feature_pre_filter': False,\n",
    " 'lambda_l1': 0.0015287350854341264,\n",
    " 'lambda_l2': 8.582661621678263e-05,\n",
    " 'num_leaves': 31,\n",
    " 'feature_fraction': 0.7,\n",
    " 'bagging_fraction': 0.6591670111857015,\n",
    " 'bagging_freq': 3,\n",
    " 'min_child_samples': 20\n",
    "    }\n",
    "    \n",
    "    model = lgb.LGBMRegressor(**lightgbm_params)\n",
    "     \n",
    "    model.fit(X_fit, y_fit, \n",
    "              eval_set=[(X_val, y_val)],\n",
    "              categorical_feature = cat_col_indices,\n",
    "              verbose=1000, # 1000 iterationごとに詳細を表示\n",
    "              early_stopping_rounds=500) # 500 iterationの間validation setの精度が向上しなかったら学習終了\n",
    "    \n",
    "    # validation setの予測結果を格納\n",
    "    cv_pred = model.predict(X_val)\n",
    "    \n",
    "    # 特徴量重要度を後で確認するためデータフレームに格納\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = feats\n",
    "    fold_importance_df[\"importance\"] = model.feature_importances_\n",
    "    fold_importance_df[\"fold\"] = counter + 1\n",
    "    \n",
    "    return model, cv_pred, fold_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40afdd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train[\"賃料\"] < 500000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec908c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for seed in seeds:\n",
    "    # 目的変数\n",
    "    train_y = np.array(train['賃料'])\n",
    "    # idは特徴量には使えないので切り出しておく\n",
    "    train_ids = np.array(train['id'])\n",
    "    # idと賃料以外が特徴量になる\n",
    "    feats = [col for col in train.columns if col not in ['id','賃料']]\n",
    "\n",
    "    # カテゴリ変数のインデックス番号を取得\n",
    "    # lightgbmでは学習時にどの特徴量がカテゴリ変数なのか引数で指定できるが、\n",
    "    # 特徴量の名前ではなく特徴量の「インデックス番号」で指定する必要がある(バージョンによっても違うかも)\n",
    "    categorical_feats_name = ['方角','建物構造','区', \"railway\", \"公示価格_bin\"]\n",
    "    categorical_feats_indices = []\n",
    "    for col in categorical_feats_name:\n",
    "        categorical_feats_indices.append(list(train[feats].columns).index(col))\n",
    "\n",
    "    # KFoldで順々に学習⇒評価していくので、最終的にtrain set全体に対するRMSEを評価するため予測結果の格納場所を用意しておく\n",
    "    cv_preds = np.zeros(train.shape[0])\n",
    "    # kf = KFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    kf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    # kf.get_n_splits(train_ids, train_y)\n",
    "\n",
    "    # パラメータチューニングしようとした残骸\n",
    "    if param_tune==True:\n",
    "        lightgbm_params = param_tune(train[feats], train_y)\n",
    "\n",
    "    # 特徴量重要度格納用タプル\n",
    "    feature_importances = []\n",
    "    # モデル格納用タプル\n",
    "    seed_models = []\n",
    "    t0 = time.time()\n",
    "    for counter, ids in enumerate(kf.split(train_ids, train_y)):\n",
    "        print('\\nseed {} Fold {}'.format(seed, counter+1))\n",
    "        # training set\n",
    "        X_fit, y_fit = train[feats].values[ids[0]], train_y[ids[0]]\n",
    "        # validation set\n",
    "        X_val, y_val = train[feats].values[ids[1]], train_y[ids[1]]\n",
    "\n",
    "        model, cv_pred, fold_importance_df = fit_lgb(X_fit, y_fit, X_val, y_val, counter, feats, categorical_feats_indices)\n",
    "        # 該当するインデックスにvalidation setの予測結果を格納\n",
    "        cv_preds[ids[1]] += cv_pred\n",
    "        models.append(model)\n",
    "        feature_importances.append(fold_importance_df)\n",
    "        del X_fit, X_val, y_fit, y_val\n",
    "        gc.collect()\n",
    "\n",
    "    # trainデータ全体のRMSEを評価\n",
    "    rmse = np.sqrt(mean_squared_error(cv_preds,train_y))\n",
    "    print('Trainデータ全体のRMSE: {:.5f}'.format(rmse))\n",
    "\n",
    "    # 特徴量重要度のプロット\n",
    "    feature_importance_df = pd.concat(feature_importances)\n",
    "    mean_importance = feature_importance_df[[\"feature\", \"importance\"]].groupby('feature').mean()\n",
    "    feature_importance_df['mean_importance'] = feature_importance_df['feature'].map(mean_importance['importance'])\n",
    "    plt.figure(figsize=(8,24), facecolor='w')\n",
    "    #plt.rcParams[\"font.size\"] = 16\n",
    "    sns.barplot(x='importance', y='feature', \n",
    "                data=feature_importance_df.sort_values('mean_importance', ascending=False).iloc[:5 * 50])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    t1 = time.time()\n",
    "    elapsed_time = t1-t0\n",
    "    print(\"Elapsed time：{:.2f} sec\".format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeef1ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "# submissionにidが必要なのでidは必ず確保しておく\n",
    "test_ids = test[\"id\"]\n",
    "\n",
    "test_preds = np.zeros(test.shape[0])\n",
    "# fold数分のモデルの予測結果を平均(アンサンブル)\n",
    "for model in tqdm(models):\n",
    "    test_preds += model.predict(test[feats].values)/len(models)\n",
    "\n",
    "submission = pd.DataFrame({\"id\":test_ids,\n",
    "                           \"賃料\":test_preds})\n",
    "\n",
    "# submissionのフォーマットにのっとって出力\n",
    "submission.to_csv(f\"./submission_log/submission_lgbm_{n}_normal.csv\", sep=\",\", index=False, header=None)\n",
    "\n",
    "t1 = time.time()\n",
    "elapsed_time = t1-t0\n",
    "print(\"Elapsed time：{:.2f} sec\".format(elapsed_time))\n",
    "cv_pred_df = pd.DataFrame([cv_preds, train_y]).T\n",
    "cv_pred_df.columns = [\"cv_score\", \"true\"]\n",
    "cv_pred_df[\"error\"] = abs(cv_pred_df[\"cv_score\"] - cv_pred_df[\"true\"])\n",
    "cv_pred_df.to_csv(f\"./cv_log/cv_error_{n}_normal.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea88df1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76abb1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
